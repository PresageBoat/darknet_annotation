[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=64
subdivisions=32
width=416
height=416
channels=3
momentum=0.949
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.000125
burn_in=4000
max_batches = 86100
policy=cosine


#cutmix=1
mosaic=1

#:104x104 54:52x52 85:26x26 104:13x13 for 416

#Downsample
[convolutional]
batch_normalize=1
filters=32
size=3
stride=2
pad=1
activation=relu

#s1
#s1-b1 s=2
[convolutional]
batch_normalize=1
filters=72
size=1
stride=2
pad=1
activation=linear

[route]
layers = -2

[convolutional]
batch_normalize=1
filters=72
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=72
size=3
stride=2
pad=1
group=3
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=8
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=72
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=96
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-9
activation=relu

#s1-b2 s=1
[convolutional]
batch_normalize=1
filters=72
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=72
size=3
stride=1
pad=1
group=3
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=18
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=72
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=72
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-8
activation=relu

#s2
#s2-b1
[convolutional]
batch_normalize=1
filters=216
size=1
stride=2
pad=1
activation=linear

[route]
layers = -2

[convolutional]
batch_normalize=1
filters=216
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=216
size=3
stride=2
pad=1
group=9
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=18
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=216
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=216
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-9
activation=relu

#s2-b2 s=1
[convolutional]
batch_normalize=1
filters=216
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=216
size=3
stride=1
pad=1
group=9
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=54
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=216
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=216
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-8
activation=relu

#s2-b3 s=1
[convolutional]
batch_normalize=1
filters=216
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=216
size=3
stride=1
pad=1
group=9
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=54
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=216
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=216
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-8
activation=relu

#s2-b4 s=1
[convolutional]
batch_normalize=1
filters=216
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=216
size=3
stride=1
pad=1
group=9
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=54
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=216
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=216
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-8
activation=relu

#s2-b5 s=1
[convolutional]
batch_normalize=1
filters=216
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=216
size=3
stride=1
pad=1
group=9
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=54
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=216
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=216
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-8
activation=relu

#s3
#s3-b1 s=2
[convolutional]
batch_normalize=1
filters=576
size=1
stride=2
pad=1
activation=linear

[route]
layers = -2

[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=576
size=3
stride=2
pad=1
group=24
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=54
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=576
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-9
activation=relu

#s3-b2 s=1
[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=576
size=3
stride=1
pad=1
group=24
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=144
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=576
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-8
activation=relu

#s3-b3 s=1
[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=576
size=3
stride=1
pad=1
group=24
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=144
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=576
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-8
activation=relu

#s3-b4 s=1
[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=576
size=3
stride=1
pad=1
group=24
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=144
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=576
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-8
activation=relu

#s3-b5 s=1
[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=576
size=3
stride=1
pad=1
group=24
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=144
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=576
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-8
activation=relu

#s3-b6 s=1
[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=576
size=3
stride=1
pad=1
group=24
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=144
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=576
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-8
activation=relu

#s3-b7 s=1
[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=576
size=3
stride=1
pad=1
group=24
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=144
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=576
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-8
activation=relu

#s3-b8 s=1
[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=576
size=3
stride=1
pad=1
group=24
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=144
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=576
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-8
activation=relu

#s3-b9 s=1
[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=576
size=3
stride=1
pad=1
group=24
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=144
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=576
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-8
activation=relu

#s3-b10 s=1
[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=576
size=3
stride=1
pad=1
group=24
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=144
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=576
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-8
activation=relu

#s3-b11 s=1
[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=576
size=3
stride=1
pad=1
group=24
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=144
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=576
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-8
activation=relu

#s3-b12 s=1
[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=576
size=3
stride=1
pad=1
group=24
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=144
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=576
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-8
activation=relu

#s3-b13 s=1
[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=576
size=3
stride=1
pad=1
group=24
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=144
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=576
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=576
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-8
activation=relu


#s4
#s4-b1 s=2
[convolutional]
batch_normalize=1
filters=1512
size=1
stride=2
pad=1
activation=linear

[route]
layers = -2

[convolutional]
batch_normalize=1
filters=1512
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=1512
size=3
stride=2
pad=1
group=63
activation=relu

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=144
size=1
stride=1
activation=swish

# excitation
[convolutional]
filters=1512
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=1008
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-9
activation=relu

###1/32#####
#decode layer only need change 
#1/16 and 1/8
##########################
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

### SPP ###
[maxpool]
stride=1
size=5

[route]
layers=-2

[maxpool]
stride=1
size=9

[route]
layers=-4

[maxpool]
stride=1
size=13

[route]
layers=-1,-3,-5,-6
### End SPP ###

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

#1/16 output as input 
[route]
layers = 166

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

#1/16 output as input
[route]
layers = -1, -3

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#1/8
[upsample]
stride=2

#1/8 output as  input 
[route]
layers = 60

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -1, -3

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

##########################

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=24
activation=linear

[yolo]
mask = 0,1,2
anchors = 11, 17,  11, 43,  29, 29,  22, 73,  52, 58,  41,138,  86,111, 111,201, 182,276
classes=3
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
scale_x_y = 1.2
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6
max_delta=5




[route]
layers = -4

[convolutional]
batch_normalize=1
size=3
stride=2
pad=1
filters=256
activation=leaky

[route]
layers = -1, -16

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=24
activation=linear


[yolo]
mask = 3,4,5
anchors = 11, 17,  11, 43,  29, 29,  22, 73,  52, 58,  41,138,  86,111, 111,201, 182,276
classes=3
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
scale_x_y = 1.1
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6
max_delta=5


[route]
layers = -4

[convolutional]
batch_normalize=1
size=3
stride=2
pad=1
filters=512
activation=leaky

[route]
layers = -1, -37

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=24
activation=linear


[yolo]
mask = 6,7,8
anchors = 11, 17,  11, 43,  29, 29,  22, 73,  52, 58,  41,138,  86,111, 111,201, 182,276
classes=3
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
scale_x_y = 1.05
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6
max_delta=5
